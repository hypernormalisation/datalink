{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import logging\n",
    "import sys\n",
    "import copy\n",
    "import collections.abc\n",
    "import json\n",
    "\n",
    "import dataset\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s | %(message)s',\n",
    "                    level=logging.DEBUG,\n",
    "                    stream=sys.stdout)\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datalink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.util import hash_pandas_object\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# np.random.seed(42)\n",
    "# arr = np.random.choice(['foo', 'bar', 42], size=(3,4))\n",
    "# df = pd.DataFrame(arr)\n",
    "\n",
    "# df\n",
    "# h = hash_pandas_object(df)\n",
    "# type(h)\n",
    "# h\n",
    "\n",
    "# arr = np.random.choice(['foo', 'bar', 42], size=(3,4))\n",
    "# df = pd.DataFrame(arr)\n",
    "# df\n",
    "# h2 = hash_pandas_object(df)\n",
    "# type(h2)\n",
    "# h2\n",
    "# h3 = h2.copy()\n",
    "# h.equals(h2)\n",
    "# h2.equals(h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO | logging from datalink\n"
     ]
    }
   ],
   "source": [
    "datalink.test_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStoreDescriptor(object):\n",
    "    \"\"\"A descriptor for the relevant key in the datastore.\"\"\"\n",
    "\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def __get__(self, instance, owner):\n",
    "        return instance._data[self.key]\n",
    "\n",
    "    def __set__(self, instance, value):\n",
    "        instance._data[self.key] = value\n",
    "        if instance._has_data_updated:\n",
    "            instance._save_state()\n",
    "            instance._set_data_hash()\n",
    "\n",
    "class DataStore:\n",
    "    db_path = None\n",
    "    table_name = None\n",
    "    _data_fields = {}\n",
    "    \n",
    "    \"\"\"Class for a basic mapping datastore.\"\"\"\n",
    "    def __init__(self, link='unique', **kwargs):\n",
    "        self._hash_previous = None\n",
    "        self._data = self._data_fields # {'a': 10, 'b': [2,3], 'c': 'a string'}\n",
    "        for key in self._data:\n",
    "            if not hasattr(self.__class__, key):\n",
    "                setattr(self.__class__, key, DataStoreDescriptor(key))\n",
    "        self._get_data_hash()\n",
    "        \n",
    "        # Establish link and attempt a load.\n",
    "        if link == 'unique':\n",
    "            self.link = datalink.UniqueLookup(table_name = self.table_name,\n",
    "                                              db_path = self.db_path,\n",
    "                                              **kwargs)\n",
    "        elif link == 'metadata':\n",
    "            self.link = datalink.NamespaceLookup(**kwargs)\n",
    "        if self.link._loaded_data:\n",
    "            self._format_loaded_data()\n",
    "    \n",
    "    # Properties for interfacing with the link to save, and to handle\n",
    "    # translation between SQL friendly data and the python objects in\n",
    "    # the data store.\n",
    "    def _save_state(self):\n",
    "        log.debug('Call to _save_state.')\n",
    "        self.link.save(self._sql_friendly_data)\n",
    "        \n",
    "    @property\n",
    "    def _sql_friendly_data(self):\n",
    "        \"\"\"\n",
    "        Property to return a version of the data store\n",
    "        with data types supported by SQL.\n",
    "        \"\"\"\n",
    "        d = copy.deepcopy(self._data)\n",
    "        for key, val in d.items():\n",
    "            if (isinstance(val, collections.abc.Sequence) and not \n",
    "                isinstance(val, str)):\n",
    "                try:\n",
    "                    d[key] = str(val)\n",
    "                except TypeError:\n",
    "                    raise\n",
    "        # Add the uuid\n",
    "        d['uuid'] = self.link.uuid\n",
    "        return d\n",
    "    \n",
    "    def _format_loaded_data(self):\n",
    "        results = list(self.link._loaded_data)\n",
    "        if len(results) != 1:\n",
    "            log.warning(f'Ambiguous uuid in loading of data,'\n",
    "                        f' received {len(results)} results.')\n",
    "        d = results[0]\n",
    "        d.pop('id')\n",
    "        d.pop('uuid')\n",
    "        for k,v in d.items():\n",
    "            try:\n",
    "                d[k] = ast.literal_eval(v)\n",
    "            except (ValueError, SyntaxError):\n",
    "                d[k] = v\n",
    "        self._data = dict(d)\n",
    "        \n",
    "    # Properties for accessing and updating the data store.\n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._data\n",
    "    \n",
    "    @property\n",
    "    def uuid(self):\n",
    "        return self.link.uuid\n",
    "    \n",
    "    def update(self, config):\n",
    "        \"\"\"\n",
    "        Update multiple properties at once.\n",
    "        Only uses descriptor directly in last call for \n",
    "        only one save call.\n",
    "        \"\"\"\n",
    "        for i, (k, v) in enumerate(config.items()):\n",
    "            if i == len(config)-1:\n",
    "                setattr(self, k, v)\n",
    "            else:\n",
    "                self._data[k] = v\n",
    "    \n",
    "    # Properties and methods for hashing data and detecting changes\n",
    "    # in the internal data store state.\n",
    "    @property\n",
    "    def _hashable_data(self):\n",
    "        \"\"\"Make any unhashable values in the data store hashable.\"\"\"\n",
    "        d = copy.deepcopy(self._data)\n",
    "        for key, val in d.items():\n",
    "            if isinstance(val, collections.abc.Hashable):\n",
    "                continue\n",
    "            else:\n",
    "                if isinstance(val, collections.abc.Iterable):\n",
    "                    try:\n",
    "                        d[key] = tuple(val)\n",
    "                    except TypeError:\n",
    "                        raise\n",
    "        return d\n",
    "    \n",
    "    def _get_data_hash(self):\n",
    "        \"\"\"\n",
    "        Creates a hash of the internal datastore, casting \n",
    "        unhashable types to hashables where possible.\n",
    "        \"\"\"\n",
    "        d = self._hashable_data\n",
    "        # Make a hash and assign it.\n",
    "        h = hash(json.dumps(d, sort_keys=True))\n",
    "        return h\n",
    "\n",
    "    def _set_data_hash(self):\n",
    "        self._hash_previous = self._get_data_hash()\n",
    "    \n",
    "    @property\n",
    "    def _has_data_updated(self):\n",
    "        new_hash = self._get_data_hash()\n",
    "        if new_hash == self._hash_previous:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "def datalink_factory(\n",
    "    db_path=None, table_name=None, data_fields=None,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Factory function to produce a new class derived from DataStore.\n",
    "    \"\"\"\n",
    "    class NewClass(DataStore):\n",
    "        pass\n",
    "    NewClass.db_path = db_path\n",
    "    NewClass.table_name = table_name\n",
    "    NewClass._data_fields = data_fields\n",
    "    return NewClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyClass = datalink_factory(db_path='~/test.db', table_name='data',\n",
    "                           data_fields={'a': None, 'b': [2,4], 'c': 'a string'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG | Creating database: /home/sogilvy/test.db\n",
      "INFO | - db created at path: /home/sogilvy/test.db\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': None, 'b': [2, 4], 'c': 'a string'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = MyClass()\n",
    "d.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 4]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'a string'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data accessible through field name\n",
    "print(d.a)\n",
    "d.b\n",
    "d.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG | Call to _save_state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sogilvy/repos/datalink/venv/lib/python3.7/site-packages/dataset/table.py:218: RuntimeWarning: Changing the database schema inside a transaction in a multi-threaded environment is likely to lead to race conditions and synchronization issues.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': 12, 'b': [2, 4], 'c': 'a string'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runtime warning results from multiple threads due to ipython usage\n",
    "d.a = 12\n",
    "d.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG | Call to _save_state.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': 14, 'b': [2, 4], 'c': 'a new string'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.update({'a': 14, 'c': 'a new string'})\n",
    "d.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9fdc6db7-d8ad-41a8-8c79-776f16cc611a'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's get the uuid and load into a new instance from the SQL database.\n",
    "d.uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n"
     ]
    }
   ],
   "source": [
    "d2 = MyClass(uuid=d.uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 14, 'b': [2, 4], 'c': 'a new string'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datalink",
   "language": "python",
   "name": "datalink"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
